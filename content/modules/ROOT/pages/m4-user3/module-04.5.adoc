:imagesdir: ../../assets/images

++++
<div class="developer">
++++


= Developer Activity: Welcome on board in "Première Classe" - Drink your own champagne!

IMPORTANT: Please make sure you are logged in as a Developer with `{dev-username}` / `{common_password}` as you were guided to in the previous step. We advise you to use a *private/incognito window* to log out properly!  

include::../style.adoc[]

## The home page dashboard

On the development home page, all tools needed are represented by different tabs, such as :

* Topology
* Issues
* CI 
* Image Registry
* Docs etc..

It maps with the following integrations performed backstage ;)

image:m3/template-components.png[]

++++
</div>
++++

It's the entry point for everything !! 

Our first mission is to add a new tab to monitor changes performed by our GitOps engine. 

NOTE: We will explore tabs through the lab guide. But don't be shy and feel free to open the tabs!

## Customize your development project dashboard 

Since the beginning of the workshop, we have leveraged GitOps mechanisms thanks to ArgoCD. As a developer, it would be nice to get an overview of the objects we manage through our development environment without leaving our new hometown. The Internal Developer Portal!
To do so, we will enable the ArgoCD view in our dashboard, freshly instantiated.
The *CD* shortcut in the dashboard will display this view :

image:m4/argocd-view.png[]

### You are the owner of your dashboard

Dashboard definition is located in the git repo instantiated to host your code base in our GitLab repository. It's a way to bring tooling and coding consistently. 
Dashboard UI components are defined in a file named *catalog-info.yaml*.
Let's open the IDE cloud, *Openshift Devspaces*, and jump into the dashboard edit!

image:m4/hero-home-page-rhdh.png[] 

You may be asked to authenticate again. Please, proceed. 
You should see the following page while the Dev Spaces are starting up:

image:m4/dev-spaces-starting-up.png[]

Open the IDE cloud here : 

image:m4/catalog-info-location.png[]

Please open the *catalog-info.yaml* and uncomment the following annotation.

* Remove the  *#* 

image:m4/uncomment-catalog-info.png[]

* It must look like this. Be sure to respect the right YAML indentation 

image:m4/uncommented-catalog-info.png[]



NOTE: The UI dashboard will be updated once the commit is done. To simplify the development flow, we'll commit later with the changes done on our code base

Confirm you have this directory : 

image:m4/fight-service-directory.png[]

## The Fight Service

The Fight service is a Quarkus intelligent service. 
Instead of randomly selecting a winner in the battle between heroes and villains, he can interact with a language model (LLM) and delegate the decision to it.
Furthermore, this consultation will not only provide a winner but also a detailed description of how the fight unfolded.

First, let’s have a look at the big picture. When integrating an LLM into a Quarkus application, 
You need to describe what you want the AI to do. 
Unlike traditional code, you are going to explain the behavior of the AI using natural language. 

The following diagram illustrates the interactions between the Fight service and the LLM.

image:m4/fight-architecture.png[]



## The Quarkus-LangChain4j Extension

This extension is based on the LangChain4j library, which provides a common API to interact with LLMs. 
The LangChain4j project is a Java re-implementation of the famous LangChain library.

#Note that the extension is already present in the `pom.xml` file of your Fight service:#

```xml
<dependency>
    <groupId>io.quarkiverse.langchain4j</groupId>
    <artifactId>quarkus-langchain4j-openai</artifactId>
    <version>${quarkus-langchain4j.version}</version>
</dependency>
```
== Configuration

Configuring OpenAI models mandates an API key or API URL among others oto



#Copy the following configuration in your `fight-service/src/main/resources/application.properties` file #

[,bash,subs=attributes]

====
quarkus.langchain4j.openai.base-url={openai-url}

quarkus.langchain4j.openai.chat-model.model-name={openai-model}

quarkus.langchain4j.openai.api-key={openai-key}

quarkus.langchain4j.openai.chat-model.temperature=1

quarkus.langchain4j.log-requests=true

quarkus.langchain4j.log-responses=true

quarkus.langchain4j.openai.timeout=60s

====


[,haskell,subs=attributes+quotes]
----
main :: IO ()
main = putStrLn "Hello, World!"
quarkus.langchain4j.openai.base-url={openai-url}
quarkus.langchain4j.openai.chat-model.model-name={openai-model}
----



**Update the values with the ones given by your teachers.**

They are self-explanatory, but you can check the documentation for more information.

## Directory Structure
Notice that by bootstrapping the project with the specific `OpenCodeQuest - AI-Infused application with Quarkus` template, you get the following directory structure with a few Java classes already created and other artifacts.

image:m4/fight-directory-structure.svg[]

It generates the following in the `fight-service` folder:

* the Maven structure with a `pom.xml`
* an `io.quarkus.workshop.fight.FightResource.java` resource exposed on `/api/fights`.
* a straightforward Java record `Fight.java` that encapsulates the hero and villain inputs for a fight.
* the corresponding `Hero.java` and `Villain.java`.
* a Java record `FightResult.java`. Quarkus automatically creates an instance of `FightResult` from the LLM’s JSON response.
* an intelligent service `FightSimulatorService.java`. This is where we will define the interaction with the LLM.
* the `application.properties` configuration file.

## Defining LLM interactions

It’s time to tell the LLM what we want to do. 
The Quarkus LangChain4J extension provides a declarative way to describe LLM interactions. 
We model the interaction using an interface annotated with `@RegisterAiService`.

## Uncomment the FightSimulatorService.java file

The file is located in *src/main/java/io/quarkus/workshop/fight/FightSimulatorService.java*

Open it and remove the first part of the file:

image:m4/start-comment-line.png[]

And the last one:

image:m4/end-comment-line.png[]




The rest of the application would be able to use the LLM by injecting the `FightSimulatorService` interface and calling the methods.

Speaking about methods, that’s where the magic happens. 
These methods accept parameters and are annotated with `@SystemMessage` and `@UserMessage` to define instructions directed to the LLM.
You should describe what you want the LLM to do using natural language. 

The system defines the scope and initial instructions, serving as the first message sent to the LLM. 
It delineates the AI service’s role in the interaction.

## User Message (Prompt)

==Notice the presence of the `@UserMessage` annotation `FightSimulatorService`==. 
It defines primary instructions dispatched to the LLM. 
It typically encompasses requests and the expected response format.
As you can note, we are using a prompt template with the following format. 
This format is expected by the model.

```
<|system|>
system prompt
<|user|>
content of the question
<|assistant|>
new line for the model's answer
```

## Parameter Passing and Referencing
AI methods can take parameters referenced in system and user messages using the {parameter} syntax. Note the `{hero}` and `{villain}` references.

### AI Method Return Type

The fight method returns a `FightResult`. The JSON response will be mapped to that object directly.


### Fault Tolerance

The distributed nature of microservices makes external communication unreliable, increasing the need for application resiliency. 
Quarkus addresses this by offering SmallRye Fault Tolerance, based on the MicroProfile Fault Tolerance specification.

In the pom, you can see the corresponding smallrye dependencies: 

```java
<dependency>
        <groupId>io.quarkus</groupId>
        <artifactId>quarkus-smallrye-fault-tolerance</artifactId>
</dependency>
```

Then, in the code, #notice the presence of the `@Timeout` annotation in the fight method#

If the LLM invocation is taking too long, the `@Timeout` annotation can stop it after 1 minute, preventing it from hanging indefinitely.

## The Fight Resource

Now, #let's take a look at the `fight-service/src/main/java/io/quarkus/workshop/fight/FightResource.java`.#
#This is a JAX-RS resource just like the Hero endpoint where the FightSimulatorService is injected.# 
#Then the intelligent `fight` method is called from the exposed `fight` method.# 

### Start the Fight service in dev mode

We are now ready to run our application.

#Open a Terminal and run one of the following commands#

`./mvnw quarkus:dev`

#or#

`quarkus dev`


## Verify the Fight service

#For verifying the Fight service is up and running, open the Developer Console by navigating to the $FIGHT_URL/q/dev-ui#

#by clicking the `Open in New Tab` button, a pop-up will be shown#

image:m4/open-quarkus-dev-in-new-tab.png[]

